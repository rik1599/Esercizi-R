---
title: "Esercizi 2"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(printr)
```

# esercizi di laboratorio su dataset

## Compito del 1 febbraio 2017

Let us consider the dataframe mtcars, which comprises the fuel
consumption and 10 aspects of design and performance for 32 automobiles
(1970s models). The help file is given below

```{r echo=FALSE, printr.help.sections="format"}
help(mtcars)
```

Describe how to perform a preliminary data analysis on this dataframe,
using suitable R commands.

```{r}
newMtcars <- mtcars
newMtcars$vs <- factor(mtcars$vs, labels = c("V-shaped", "straight"))
newMtcars$am <- factor(mtcars$am, labels = c("automatic", "manual"))
```

Il dataset contiene una serie di dati su diversi modelli di automobili,
tra cui i consumi di carburante (per miglio) e una serie di aspetti
tecnici legati al design e alle performance dell'auto. Diamo un'occhiata
alle variabili:

```{r}
summary(newMtcars)
```

Osservazioni:

-   sono presenti 9 variabili numeriche e 2 categoriali,

-   le variabili categoriali (vs e am) sono di tipo nominale,

-   mpg, disp, hp, drat, wt e qsec sono di tipo continuo,

-   cyl, gear e carb sono di tipo discreto (valori interi),

mpg rappresenta i consumi del modello in miglia percorsi con un gallone
di carburante. Per il significato delle altre variabili si suggerisce di
consultare l'help.

Supponendo che la nostra analisi sia focalizzata sullo studio dei
consumi dei veicoli. Ora ci si concentra sulle caratteristiche della
variabile mpg.

Si parte da una panoramica sulla distribuzione di frequenza e dei
quantili

```{r}
par(mfrow = c(1,2))
hist(newMtcars$mpg, breaks = 10 + (0:10) * 2.4)
hist(newMtcars$mpg, breaks = 10 + (0:10) * 2.4, probability = T)
lines(density(newMtcars$mpg))
abline(v=mean(newMtcars$mpg), col=2)
abline(v=median(newMtcars$mpg), col=3)
par(mfrow = c(1,1))
boxplot(newMtcars$mpg, horizontal = T)
```

Osservazioni:

-   la densità presenta un andamento simil-normale, con un picco
    inferiore sia alla media che alla mediana, e un massimo locale sulla
    coda destra, appesantendola di conseguenza,

-   sia dagli istogrammi che dal boxplot si osserva una asimmetria,

-   non si nota la presenza di particolari outlier,

-   nonostante tutto, la media non è molto distante dalla mediana.

```{r}
library(moments)
skewness(newMtcars$mpg)
kurtosis(newMtcars$mpg)
```

Osservazioni:

-   skewness abbastanza bassa, leggera asimmetria verso destra

-   curtosi non troppo distante da 3, quindi la distribuzione è
    leggermente di tipo iponormale

Vista la particolare distribuzione dei dati si potrebbe considerare di
partizionare il dataset in veicoli a basso consumo (mpg \< 25) e ad alto
consumo (mpg $\leq$ 25), oppure considerare una trasformata della
variabile (es. logaritmo)

```{r}
logMtcarsMpg <- log(newMtcars$mpg)
summary(logMtcarsMpg)

breaks <- 2 + (0:10) * 0.2
par(mfrow = c(1,2))
hist(logMtcarsMpg, breaks = breaks)
hist(logMtcarsMpg, probability = T, breaks = breaks)
lines(density(logMtcarsMpg))
abline(v=mean(logMtcarsMpg), col=2)
abline(v=median(logMtcarsMpg), col=3)
par(mfrow = c(1,1))
boxplot(logMtcarsMpg, horizontal = T)

skewness(logMtcarsMpg)
kurtosis(logMtcarsMpg)
```

Osservazioni:

-   con il logaritmo si ottiene una maggiore simmetria del grafico, a
    scapito di una leggera diminuzione dell'indice di curtosi

Proviamo a ricercare delle ipotetiche correlazioni tra mpg e le altre
variabili:

### Variabili continue

```{r}
par(mfrow=c(2,3))
for (i in c("disp", "hp", "drat", "wt", "qsec")) {
  plot(newMtcars[, i], newMtcars$mpg, xlab = i, ylab = "mpg")
  lines(lowess(newMtcars[, i], newMtcars$mpg), col=1)
  abline(lm(newMtcars$mpg~newMtcars[, i]), col=2)
}
par(mfrow=c(1,1))
```

### Variabili discrete

```{r}
par(mfrow = c(1,3))
boxplot(mpg~cyl, data = newMtcars)
boxplot(mpg~gear, data = newMtcars)
plot(mpg~carb, data = newMtcars)
lines(lowess(newMtcars$carb, newMtcars$mpg), col=1)
abline(lm(mpg~carb, data = newMtcars), col=2)
par(mfrow = c(1,1))
```

### Variabili categoriali

```{r}
par(mfrow=c(1,2))
boxplot(mpg~vs, data = newMtcars)
boxplot(mpg~am, data = newMtcars)
par(mfrow=c(1,1))
```

Dai grafici si può ipotizzare che:

-   le variabili vs, arm e cyl sembrano avere una forte influenza su mpg
-   per quanto riguarda qsec e drat la correlazione sembra essere
    presente ma è molto leggera
-   per quanto riguarda wt, disp e hp sembra esserci una correlazione,
    ma non è detto che sia di tipo lineare.

```{r}
cor(x = newMtcars$wt, y = newMtcars$mpg, method = "pearson")
cor(x = newMtcars$disp, y = newMtcars$mpg, method = "pearson")
cor(x = newMtcars$hp, y = newMtcars$mpg, method = "pearson")
cor(x = newMtcars$hp, y = newMtcars$mpg, method = "spearman")
```

Gli indici di correlazione di pearson confermano la presenza di correlazioni lineari negative (discrete) per wt e disp. Per quanto riguarda hp, la relazione lineare c'è ma è meno significativa, tuttavia il coefficiente di spearman conferma l'esistenza di una correlazione.

A seguito di quanto visto anche dai grafici, proviamo a considerare una trasformazione di hp per cercare una correlazione migliore. 


```{r}
par(mfrow=(c(1,2)))
plot(newMtcars$hp, newMtcars$mpg, xlab = "hp", ylab = "mpg")
lines(lowess(newMtcars$hp, newMtcars$mpg), col=1)
abline(lm(newMtcars$mpg~newMtcars$hp), col=2)

plot(1/newMtcars$hp, newMtcars$mpg, xlab = "1/hp", ylab = "mpg")
lines(lowess(1/newMtcars$hp, newMtcars$mpg), col=1)
abline(lm(newMtcars$mpg~I(1/newMtcars$hp)), col=2)
par(mfrow=(c(1,1)))
```

Sembra esserci una buona correlazione lineare tra mpg e il reciproco di hp.

```{r}
cor(x = newMtcars$mpg, y = 1/newMtcars$hp, method = "pearson")
```


After fitting the model
`fit <- lm(mpg ∼ disp + hp + wt + drat, data=mtcars)`, the following
outputs are obtained by the R commands `summary(fit)` and `plot(fit)`,
respectively.
Describe how to interpret these results, and then suggest how to proceed
with further analyses.

```{r echo=FALSE}
fit <- lm(mpg ~ disp + hp + wt + drat, data=mtcars)
summary(fit)
```
### Osservazioni
-   Modello su quattro regressori continui

-   si nota l'intercetta molto elevata e ha il p-value più basso

-   il regressore disp ha un p-value elevato (ca. 72%), quindi la sua influenza sul risultato è ininfluente

-   analogo discorso vale per drat (p-value ca. 19%)

-   hp e wt risultano essere i regressori più influenti all'interno del modello, entrambi negativi e con p-value abbastanza bassi da tenerli nel            modello.

-   si osserva che i coefficienti di wt, drat e l'intercetta sono molto più elevati rispetto agli altri coefficienti.
    potrebbe indicare la necessità di normalizzare i dati per gestire meglio la diversità delle scale di ciascuna variabile
    
-   dagli indici $R^2$ concludiamo che copriamo abbastanza bene la variabilità della variabile risposta con il modello

-   il risultato del test F conferma quanto detto in precedenza

```{r}
par(mfrow = c(2,3))
plot(fit, which = c(1:6))
par(mfrow=c(1,1))
```

Oss. 

- Dal primo grafico, si osserva che la varianza dei residui non è costante. In particolare, per alcuni valori estremi si riscontrano residui significativi (che risultano tali anche quando standardizzati)

- Il secondo grafico evidenzia che i residui standardizzati si discostano significativamente dai quantili teorici per i valori non centrali.

- Dal quinto grafico si osserva un effetto leva non necessariamente corrispondente ad un alto residuo. Le distanze di cook sono contenute, quindi si può affermare che nessun punto è particolarmente influente (ci sono un paio di punti vicini alla soglia del 0.5). Il grafico delle distanza di Cook sostanzialmente conferma questa supposizione, evidenziando i tre valori critici.



Da tali diagnostiche, assieme a quanto emerso dal primo grafico, si osserva che sarebbe appropriato valutare modelli più complessi, magari che escludano i predittori che ottenuto un p-value alto nei test sui coefficenti e che considerino trasformate di alcuni regressori (come ad esempio 1/hp invece di hp).

In alternativa, potrebbe essere utile indagare ulteriormente sui punti segnalati dalle diagnostiche e valutare di rimuoverli dal modello.


```{r}
summary(fit$model$mpg)
summary(fit$model$hp)
summary(fit$model$wt)

```


```{r}
fit$model[c("Toyota Corolla", "Chrysler Imperial", "Maserati Bora", "Fiat 128"), ]
```

Si osserva ad esempio che l'oss. "Toyota Corolla" risulta avere un valore estremo per mpg (il massimo), e risulta anche essere nel primo quartile per quanto riguarda le variabili hp e wt. 

## Compito del 13 febbraio 2017

Let us consider the dataframe bp.obese of the library ISwR, which
comprises information about sex, obesity and blood pressure for a random
sample of 102 Mexican-American adults in a small California town. The
help file and the output of the str command are given below

```{r, echo=FALSE, printr.help.sections="format"}
library(ISwR)
help(bp.obese)
summary(bp.obese)
```

The aim of the study is to analyze the potential relationship between
blood pressure, which is the response variable, and obesity, taking into
account also the factor regressor sex. Describe how to perform a
preliminary data analysis on this dataframe, using suitable R commands
and comment the following plot.

![](img/img1.png)


Il seguente plot mette il relazione la variabile obesità con la variabile bp, tenendo conto anche del fattore sesso (che viene riportato attraverso il colore dei punti sul plot). 

Si osserva che ai punti si sovrappongono anche due rette di regressione (una per il fattore maschio, una per il fattore femmina). Se si dovesse effettuare qualche considerazione molto generale, si può dire che a colpo d'occhio si nota che:

* tutti i valori più estremi per la variabile obesità sono femmine, mentre per quanto riguarda la variabile bp non ci sono grosse differenze (anche se i maschi tendono ad avere un valore un po' più elevato)
* la retta di regressione per i maschi mostra come essi tendono - di base - ad avere bp elevata anche a fronte di non obesità; al contrario, la retta relativa alle femmine ha un intercetta più bassa ma anche una pendenza (leggermente) più elevata. Ciò sembra indicare che il fattore obesità sia più rilevante per le femmine
* attenzione però, questa affermazione potrebbe essere affrettata, in quanto nei nostri dati non abbiamo osservazioni relative a maschi fortemente obesi e pertanto non abbiamo una visione completa.


### Analisi preliminare

Partiamo con una panoramica rapida del dataset.

```{r}
help(bp.obese)
summary(bp.obese)
```

Il dataset è costituito da tre variabili, due numeriche continue (obese e bp) e una categoriale non ordinale (sex). 

Trasformiamo la variabile categoriale in un fattore.

```{r}
bp.obese2 <- bp.obese
bp.obese2$sex <- factor(bp.obese$sex, labels = c("male", "female"))
summary(bp.obese2)

```



```{r}
# breaks <- 2 + (0:10) * 0.2
par(mfrow = c(1,2))
hist(bp.obese2$bp) # , breaks = breaks)
hist(bp.obese2$bp, probability = T, ylim=c(0, 0.025)) #, breaks = breaks)
lines(density(bp.obese2$bp))
abline(v=mean(bp.obese2$bp), col="red")
abline(v=median(bp.obese2$bp), col="green")
par(mfrow = c(1,1))
```

```{r}
boxplot(bp.obese2$bp, horizontal = T)
```

Per quanto riguarda la variabile bp si osserva una distribuzione simil normale, ma caratterizzata da una grande concentrazione di osservazioni per le classi centrali e da un'apparente assimetria verso sinistra. La media risulta maggiore rispetto alla mediana, probabilmente questo è causato da alcuni outlyer e più in generale da una coda lunga a destra. 

```{r}
par(mfrow = c(1,2))
hist(bp.obese2$obese) # , breaks = breaks)
hist(bp.obese2$obese, probability = T,) #, breaks = breaks)
lines(density(bp.obese2$obese))
abline(v=mean(bp.obese2$obese), col="red")
abline(v=median(bp.obese2$obese), col="green")
par(mfrow = c(1,1))
```


```{r}
boxplot(bp.obese2$obese, horizontal = T)
```

La variabile obese invece nel suo complesso risulta più simmetrica, se non fosse per pochi outlyer (che tra l'altro, come si è visto dal plot fornito all'inizio sono tutte oss. relative al fattore femmina, pertanto potrebbero portare ad un bias).

```{r}
library(moments)
skewness(bp.obese2$obese)
kurtosis(bp.obese2$obese)

skewness(bp.obese2$bp)
kurtosis(bp.obese2$bp)
```

In entrambi i casi, gli indici riportano un'elevata curtosi (>3, leptocurtosi, la campana risulta stretta) e un'assimetria destra (probabilmente dovuta agli outlyer). Visto che ci interessa la normalità di bp, proviamo a rimuovere gli outlyer

```{r}

bp.obese3 <- bp.obese2[bp.obese2$bp<=180, ]

summary(bp.obese3$bp)
skewness(bp.obese3$bp)
kurtosis(bp.obese3$bp)

hist(bp.obese3$bp, probability = T) #, breaks = breaks)
lines(density(bp.obese3$bp))
abline(v=mean(bp.obese3$bp), col="red")
abline(v=median(bp.obese3$bp), col="green")

```

Si osserva dagli indici che ciò migliora molto sia l'indice di di simmetria che di curtosi. Per il momento proseguiamo l'analisi con i dati completi, ma teniamo aperta la possibilità di rimuovere gli outlyer se riscontriamo problematiche con il modello.

Infine, per quanto riguarda la variabile sex già dal summary si nota che abbiamo leggermente più osservazioni per il livello femmina.


Proviamo ora a mettere in relazione le tre variabili tra di loro:

```{r}

par(mfrow=c(1,3))

plot(bp.obese2$obese, bp.obese2$bp)
lines(lowess(bp.obese2$obese, bp.obese2$bp), col=1)
abline(lm(bp~obese, data = bp.obese2), col=2)

boxplot(bp~sex, data = bp.obese2)

boxplot(obese~sex, data = bp.obese2)

par(mfrow=c(1,3))
```

Dal primo grafico, si osserva una vaga correlazione lineare tra obese e bp. Detto ciò, si osserva anche che tale correlazione sembra essere piuttosto debole, vista l'alta variabilità di bp.

```{r}
cor(bp.obese2$obese, bp.obese2$bp, method = "pearson")
```

Il bassisimo coefficente di correlazione di Pearson sostiene questa teoria.

Per quanto riguarda la relazione tra tra sex e bp, si osserva che:

* i maschi presentano una bp meno variabile rispetto alle femmine

```{r}
mean(bp.obese2[bp.obese2$sex=="male", "bp"])
mean(bp.obese2[bp.obese2$sex=="female", "bp"])
var(bp.obese2[bp.obese2$sex=="male", "bp"])
var(bp.obese2[bp.obese2$sex=="female", "bp"])
```
* seppur dal plot iniziale sembra che i valori dei maschi siano più alti di quelli delle femmine, non è così tanto vero (come si può osservare dal boxplot e dalla media)

* i valori estremi riguardano ambo i sessi

* considerazioni simili si possono effettuare anche escludendo gli outlyer più significativi

```{r}
mean(bp.obese3[bp.obese3$sex=="male", "bp"])
mean(bp.obese3[bp.obese3$sex=="female", "bp"])
var(bp.obese3[bp.obese3$sex=="male", "bp"])
var(bp.obese3[bp.obese3$sex=="female", "bp"])
```


Infine, nel dataset preso in esame, le osservazioni con alto indice di obesità tendono ad essere soprattutto donne. E' bene tenere in considerazione questo fattore per l'analisi formale successiva, onde evitare di creare bias.






After fitting these linear models
`fit1 <- lm(bp ∼ obese,data=bp.obese)`,
`fit2 <- lm(bp ∼ obese+sex,data=bp.obese)` and
`fit3 <- lm(bp ∼ obese*sex,data=bp.obese)`, the following outputs are
obtained by the R function summary.

```{r echo=FALSE}
fit1 <- lm(bp ~ obese,data=bp.obese)
fit2 <- lm(bp ~ obese+sex,data=bp.obese)
fit3 <- lm(bp ~ obese*sex,data=bp.obese)

summary(fit1)
summary(fit2)
summary(fit3)
```

Describe how to interpret these results, and then suggest how to proceed
with further analyses.

## Compito del 15 febbraio 2018

Let us consider the dataframe SAheart of the library ElemStatLearn,
which comprises information about a retrospective sample of males in a
heart-disease high-risk region of the Western Cape, South Africa. The
help file and the output of the str command are given below

```{r, echo=FALSE, printr.help.sections="format"}
library(ElemStatLearn)
help(SAheart)
str(SAheart)
```

The aim of the study is to analyze the potential relationship between
the binary response variable chd and the explanatory variables
considered in the dataframe. Describe how to perform a preli- minary
data analysis on this dataframe, using suitable R commands, and comment
the following plot.

![](img/img2.png)

With the command
`mod0 <- glm(chd ∼ ldl, data = SAheart, family = binomial)`, a simple
logistic regression model is defined for describing the potential effect
of the level of ldl on the probability of coronary heart disease.
Comment the model fitting outcomes given by the function summary.

```{r echo=FALSE}
mod0 <- glm(chd ~ ldl, data = SAheart, family = binomial)
summary(mod0)
```

After fitting these two further logistic regression models
`mod1 <- glm(chd ∼ ., data = SAheart, family = binomial)` and
`mod2 <- glm(chd ∼ tobacco + ldl + famhist + typea + age + ldl:famhist, data = SAheart, family = binomial)`,
the following outputs are obtained by the R function summary.

```{r echo=FALSE}
mod1 <- glm(chd ~ ., data = SAheart, family = binomial)
mod2 <- glm(chd ~ tobacco + ldl + famhist + typea + age + ldl:famhist, data = SAheart, family = binomial)

summary(mod1)
summary(mod2)
```

Describe how to interpret these results, and then suggest how to proceed
with further analyses.

## Compito del 11 giugno 2018

Let us consider the dataframe `house`, which includes information about
the price, the size, the floor, the number of bedrooms (bed) and the
number of bathrooms (bath) of 546 houses. The output of the str command
is given below

```{r echo=FALSE}
house <- read.table("./data/house-prices.dat", header=TRUE)
str(house)
```

A suitable linear regression model can be defined in order to study the
potential relationship between the price, which is the response
variable, and the explanatory variables considered in the dataframe.
Describe how to perform a preliminary data analysis on this dataframe,
using suitable R commands. Moreover, consider the following plots and
discuss the possibility of measuring the variables price and size in the
logarithmic scale.

![](img/img3.png)

After fitting the regression model
`fit <- lm(log(price) ∼ log(size) + bed + bath + floor, data=house)`,
the following outputs are obtained by the R commands `summary(fit)` and
`plot(fit)`, respectively.

```{r echo=FALSE, eval=FALSE}
fit <- lm(log(price) ~ log(size) + bed + bath + floor, data=house)
summary(fit)
plot(fit, lwd = 2, which = c(1:6))
```

Describe how to interpret these results, and then suggest how to proceed
with further analyses with particular regard to prediction.

## Compito del 4 febbraio 2019

Let us consider the dataframe `wages`, which containes information about
3294 USA working individuals. The data are taken from the National
Longitudinal Survey and are related to 1987. The variable as are listed
below and the output of the `str` command is given

| A data frame with 3294 observations on the following 4 variables.
| exper
|    experience in years
| male
|   1 male, 0 female
| school
|    years of schooling
| wage
|    wage (in 1980\$) per hour
| region
|    Center, North, South

```{r echo=FALSE, printr.help.sections="format"}
wages <- read.table("./data/Wages-New.txt", header = TRUE)
wages$male <- factor(wages$male)
wages$region <- factor(wages$region)
str(wages)
```

The aim of the study is to analyze the potential relationship between
the response variable wage and the explanatory variables considered in
the dataframe. Describe how to perform a preliminary data analysis on
this dataframe, using suitable R commands. Moreover, consider the
following plots and discuss the possibility of measuring the variable
`wage` in the logarithmic scale

![](img/img4.png)

In order to describe the effect of the factor male on the response
log(wage) we may analize this plot, where the probability distribution
of log(wage) is represented by considering the kernel density estimates
conditioned on the two levels (1 male, 0 female) of the variable male

![](img/img5.png)

With the commands `mod.0<-lm(log(wage) ∼ male,data=wages)` and
`mod.1<-lm(log(wage) ∼ exper*male, data=wages)`, two regression models
are defined for describing the potential effect of male and exper on the
response log(wage). Comment the model fitting outcomes given by the
function summary (Hint: consider the fact that the average years of
experience in the sample is lower for women than for men).

```{r echo=FALSE}
mod.0 <- lm(log(wage) ~ male,data=wages)
mod.1 <- lm(log(wage) ~ exper*male, data=wages)

summary(mod.0)
summary(mod.1)
```

Finally, a complete regression model is fitted
`mod.2 <- lm(log(wage) ∼., data=wages)` and the following output is
obtained by the R function summary.

```{r echo=FALSE}
summary(lm(log(wage) ~., data=wages))
```

Describe how to interpret these results, and then suggest how to proceed
with further analyses.

## Compito del 21 febbraio 2019

Let us consider the data frame loan, which contains information about
42,535 loans ranging from 1,000 \$ to 35,000 \$, issued by a company
called Lending Club. The following variables are considered: good (the
behaviour of the client with values good and bad), fico (the FICO credit
score measuring the client credit worthiness), purpose (the intended use
of the loan, with 8 different categories), loan amt (the credit amount
in \$) and income (the annual income in \$ of the client). The variable
as are listed below and the output of the str command is given

```{r echo=FALSE, printr.help.sections="format"}
loan <- read.table("./data/loan.txt", header = TRUE)
loan$good <- factor(loan$good)
loan$purpose <- factor(loan$purpose)
str(loan)
```

Moreover, the output of the command summary is also given

```{r echo=FALSE}
summary(loan)
```

The aim of the study is to analyze the potential relationship between
the response variable good and the explanatory variables considered in
the data frame, in order to evaluate the possible good/bad behaviour of
a customer. Describe how to perform a preliminary data analysis on this
data frame, using suitable R commands. Moreover, consider and discuss
the following plots

![](img/img6.png)

In order to describe the effect of the factor fico on the response good
we consider a simple logistic regression model fitted using the command
`mod.1<-glm(good ∼ fico, data = loan, family = "binomial")`. Comment the
model fitting outcomes given by the function summary and the output
given by the subsequent commands.

```{r}
mod.1 <- glm(good ~ fico, data = loan, family = "binomial")
summary(mod.1)

exp(coef(mod.1))
test <- data.frame(fico=c(700,750))
test$pred <- predict(mod.1,test, type="response")
test
```

Two further logistic regression models are fitted using
`mod.2<-glm(good ∼ fico + loan_amnt, data = loan, family = "binomial")`
and
`mod.3<-glm(good ∼ fico + loan_amnt + income + purpose, data = loan, family = "binomial")`.
Comment the corresponding output obtained by the R function summary and
then suggest how to proceed with a further predictive analysis.

```{r echo=FALSE}
summary(glm(good ~ fico + loan_amnt, data = loan, family = "binomial"))
summary(glm(good ~ fico + loan_amnt + income + purpose, data = loan, family = "binomial"))
```

## Compito del 28 gennaio 2020

Let us consider the dataframe birthwt, which contains data on 189 births
at the Baystate Medical Centre, Springfield, Massachusetts during 1986.
The focus is on the variables listed below

```{r echo=FALSE, printr.help.sections="format"}
library(MASS)
help("birthwt")
```

The aim of the study is to analyze the potential relationship between
the response variable bwt and the explanatory variables age and race.
Describe how to perform a preliminary data analysis on this dataframe
using suitable R commands and comment the following plots

![](img/img7.png)

In order to describe the potential relationship between birth weight and
age, taking into account also the factor race, we compare the following
nested models

```{r}
bwt.lm1 <- lm(bwt ~ 1 , data = birthwt)
bwt.lm2 <- lm(bwt ~ age, data = birthwt)
bwt.lm3 <- lm(bwt ~ race + age, data = birthwt)
bwt.lm4 <- lm(bwt ~ race*age, data = birthwt)
```

Describe the four models and comment the results given by the Analysis
of Variance Table, reported below. Moreover, propose some alternative
model selection procedures.

```{r}
anova(bwt.lm1, bwt.lm2, bwt.lm3, bwt.lm4)
```

Let us consider Model 3 and comment the output obtained by the R
functions summary and plot.

```{r echo=FALSE}
summary(bwt.lm3)
plot(bwt.lm3, which = c(1:4))
```

Finally, discuss the following graphical output and then suggest how to
proceed with further analyses.

![](img/img8.png)

## Compito del 18 febbraio 2020

Let us consider the dataframe wine, which contains information about 178
samples of wines grown in the same region in Italy. The cultivar of each
wine sample is observed (variable cultivar, with labels 1, 2, 3),
together with the concentration of the 13 different chemicals (variables
V1-V13). Describe how to perform a preliminary data analysis on this
dataframe using suitable R commands and comment the following outputs.

```{r}
wine <- read.table("./data/wine.txt", header = TRUE)
summary(wine)
sapply(wine[2:14],sd)
```

Moreover, discuss the results given by the scatterplot matrix considered
below, which considers the first 5 numerical variables, with colours
indicating cultivar 1 (black), cultivar 2 (red) and cultivar 3 (blue).

![](img/img9.png)

The aim of the study is to adequately synthesize the information given
by the original variables V1-V13, in order to capture as much of the
information as possible. A further objective is to use some of these new
derived variable for distinguishing the three different cultivars. The
Principal Components Analysis procedure is applied. Present the main
features of this stati- stical procedure, describe the arguments
specified below in the function princomp and discuss the output of the
function loadings.

```{r}
wine.pca <- princomp(wine[2:14], cor=TRUE)
loadings(wine.pca)[,1:4]
```

Moreover, discuss the following graphical outputs

![](img/img10.png)

![](img/img11.png)

Finally, comment this last plot, with particular concern to the aim of
characterizing the three different cultivars.

![](img/img12.png)
