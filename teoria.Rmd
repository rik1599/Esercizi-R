---
title: "Domande teoria"
author: "Riccardo Belliato - Emanuele Lena"
date: "12/19/2021"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Compito del 1 febbraio 2017

### Describe what are the aims of Exploratory Data Analysis and present the main numerical summaries for bivariate data.

L'analisi esplorativa è finalizzata ad esplorare i dati e rilevare ciò che poi si approfondirà nell'analisi formale. In particolare si vuole:

* identificare unità statistiche e variabili;
* individuare le carattersitiche principali delle variabili (di che tipo sono, a quali distribuzione di probabilità/frequenza sono associabili, ecc.);
* individuare potenziali relazioni tra le variabili.

In generale, l'obiettivo dell'analisi esplorativa è prendere confidenza con i dati, individuare le loro caratteristiche principali e formulare ed iniziare ad esplorare diverse ipotesi. Le ipotesi da esplorare potrebbero essere quelle pregresse (ciò che si supponeva prima e che ha spinto a voler fare l'analisi), oppure nuovi aspetti emersi dai dati. Sostanzialmente, lo scopo dell'analisi esplorativa è dare una direzione all'analisi formale ed individaure gli aspetti che meritano approfondimento formale.

Le principali sintesi numeriche per i dati bivariati sono, nel caso di variabili numeriche:

* la covarianza (campionaria), cioè una misura della relazione lineare - positiva o negativa - tra due variabili;
* il coefficente di correlazione di Pearson, per quantificare in la relazione lineare con un valore standardizzato (sempre appartenente all'intervallo [-1,1]);
* i più generici coefficenti di Spearman e Kendal, per individuare rispettivamente le relazioni tra i ranghi e tra le coppie di osservazioni.

Per le variabili categoriali invece si utilizzano i conteggi (aggregati in tabelle di contingenza, che permettono di analizzare le frequenze congiunte di ogni combinazione di livelli) oppure se si vuole usare un approccio più numerico e formale, l'indice chi-quadro (una misura della distanza tra le frequenze di una tabella di contingenza e le frequenze attese in caso di indipendenza). 


### Define the multiple linear regression model and highlight the basic assumptions.


### Describe the least squares estimators for the regression parameters and define a suitable estimator for the variance parameter.


### Discuss the usefulness of the fitted regression model for inferential and prediction purposes.


### Define the confidence intervals for both the regression parameters and the regression line and specify the prediction interval for a future response variable.



## Compito del 13 febbraio 2017

### Describe the purpose of an interval estimation procedure.

Lo scopo di una procedura di stima d'intervallo è definire, per un certo valore non noto, un insieme di valori (solitamente un intervallo $[U,V]$) t.c. , con una probabilità $1-\alpha$, l'intervallo contiene il valore reale. Tale procedura si svolge partendo da dei dati (riportabili ad un modello dove la distribuzione e i quantili sono noti) e un livello di confidenza desiderato $1-\alpha$ (e.g., 95%, 99%, ecc.).

Visto che si vuole ricavare un intervallo $[U,V]$ t.c. $P(U \le \theta \le V)=1-\alpha$, si immagina - ad esempio - di normalizzare (o studentizzare) i dati "centrandoli" nel valore osservato $\hat{\theta}$. A questo punto, conoscendo dove si trovano i quantili, si possono individuare i valori dell'intervallo.

Se i dati sono riconducibili ad una distribuzine normale con varianza nota - ad esempio - il problema diventa $P(\hat{\theta}+z_{\alpha/2}*SE(\hat{\theta}) \le \theta  \le \hat{\theta}-z_{\alpha/2}*SE(\hat{\theta}))=1-\alpha$, , ciò si traduce nel calcolo dell'intervallo $[\hat{\theta} \pm z_{\alpha/2}*SE(\hat{\theta})]$, dato $z_{\alpha/2}$ noto. 

### Give the right statistical interpretation of an observed 95% confidence interval for an interest parameter.

Se osservo un'intervallo di confidenza del 95% su un certo parametro d'interesse, vuol dire che, con una probabilità del 95%, l'intervallo selezionato contiene il valore reale ignoto del parametro.

Ciò vuol dire che se ripetessi l'esperimento di individuazione dell'intervallo usando come dati un numero sufficientemente grande di campioni casuali, il 95% degli intervalli conterrebbe il varlore reale.

### Present a simple application regarding the estimation of a population mean.

Si immagini di aver raccolto un campione casuale di dati numerici continui, riconducibili ad una distribuzione normale. 

Per stimare la media della popolazione, si usa come stimatore la media campionaria $\bar{Y}$. Tale stimatore è consistente, non distorto, può essere approssimato con una distribuzione normale $\bar{Y} ~ N(\mu, \sigma^2/n)$ e presenta $MSE=\sigma^2/n$ (in quanto stimatore non distorto, il suo MSE equivale alla varianza). Il suo standard error è lo standard error della media $SEM=S/\sqrt{n}$ (dove $S^2$ è uno stimatore per $\sigma^2$). 

Uno step successivo a tale stima potrebbe essere la stima di un intervallo di confidenza di lv. $1-\alpha$ $[\bar{y} \pm z_{\alpha/2}*SE(\bar{y})]$ (oppure $[\bar{y} \pm t_{\alpha/2}*SE(\bar{y})]$ se la varianza non è nota).

### List some useful steps in the model fitting procedure.

      
### Recall the main statistical indices and procedures for model assessment and model selection.

Per valutare e confrontare modelli si possono utilizzare verifiche grafiche, indici statistici e procedure di test. Per quanto riguarda le verifiche grafiche, gli strumenti a disposizione sono il plot dei quantili osservati rispetto a quelli teorici attesi e - specialmente per i modelli di regressione - il plot dei residui (standardizzati e non) rispetto ai modelli stimati.

I principali indici utilizzabili invece sono AIC (Akaike Information Criteria), BIC (Bayesian Information Criteria) e il Cross Validation Score (CV). AIC e BIC stimano la bontà di un modello bilanciando valorizzando da una parte la log-sogmiglianaza (logaritmo della funzione di densità del modello sui dati osservati e con certi parametri), dall'altra la complessità (dimensione dei parametri).  

$AIC = -2l(\hat{\theta; y})+2dim(\theta)$, $BIC = -2l(\hat{\theta; y})+log(n)*dim(\theta)$

Per entrambi gli indici, quando si confrontano più modelli, si tende a scegliere il modello che ottiene un punteggio più basso. Nel caso di BIC vengono penalizzati di più i modelli complessi (cioè quelli che richiedono di stimare un grande numero di parametri).

Il terzo indice - CV - utilizza la tecnica della cross validation per verificare la capacità di un certo modello a stimare osservazioni non incluse nei dati di training. L'idea è di creare n modelli, ciascun modello di crea stimando $\hat\theta$ considerando tutti i dati tranne l'osservazione $y_i$. A quel punto, si calcola l'indice CV come (-) la sommatoria dei logaritmi delle densità stimate per l'oss. i dal modello i-esimo (quello che esclude $y_i$). Anche in questo caso, i migliori modelli sono quelli che ottengono punteggio più basso.

Per quanto riguarda le procedure infine si hanno:
* i test parametrici per la comparazione di modelli alternativi innestati (dove si tiene come ipotesi nulla un modello semplificato e come ipotesi alternativa un modello più sofisticato che "aggiunge" parametri/complessità al modello semplice). Tali test parametrici sono usati specialmente nei contesti della regressione lineare multivariata.
* i test di goodness of fit, cioè test che fissano come ipotesi nulla la compatibilità del modello con i dati.

[vedere se è il caso di aggiungere qualcosa su ANOVA o altro]

## Compito del 15 febbraio 2018

### Describe the purpose of a point estimation procedure.

Una procedura di stima di un punto ha come scopo principare l'individuazione di una stima appropriata di un certo valore fisso non noto; tale stima ci si aspetta sia un valore sostenuto dai dati disponibili e che riveli informazioni "sul sistema" che ha generato tali dati

Il valore ignoto potrebbe essere una sintesi dei dati (la cui stima è di per se un'informazione), oppure anche un parametro di un modello che descrive i dati.


### List the main property of an estimator and define the standard error.

Uno stimatore è una statistica campionaria, ricavata da dei dati osservati, con lo scopo di effattuare una stima puntuale su un valore ingnoto. 

Essendo i dati campionari variabili casuali, lo stimatore è sua volta una variabile casuale ed è caratterizzato da un valore medio, una variabilità e una distribuzuione. Un buon stimatore:

1. è non distorto, cioè la sua media campionaria è uguale al valore reale (o almeno non è troppo distante da esso);
2. ha una variabilità contenuta (bassa varianza);
3. è consistente, cioè segue la legge debole dei grandi numeri (con un numero sufficentemente grande di osservazioni, il suo valore converge per probabilità al valore reale).

Lo standard error può essere definito come una misura della precisione di una stima. A livello teorico, lo SE è la radice dell'MSE (Mean Sqare Error), che corrisponde alla media dei quadrati degli scostamenti del valore stimato da quello reale. L'MSE può anche essere visto come la somma della varianza dello stimatore e del quadrato dello scostamento del valore medio (dello stimatore) da quello reale. 

$SE = \sqrt{MSE}$, con $MSE=E[ (\hat{\theta} - \theta)^2 ] = V(\hat{\theta}) + [E(\hat{\theta}) - \theta]^2$ (nota: si osserva che se uno stimatore è non distorto, il suo MSE equivale alla sua varianza).

Rispetto all'MSE, un vantaggio del SE è che la sua unità di misura è la stessa del valore stimato.

Nel caso pratico, ogni stima puntale viene accompagnata anche nda una stima del dello standard erro (o dell'MSE). Se uno stimatore è non distorto, tale stima può essere la radice della varianza campionaria dello stimatore.

### Present a simple application regarding the estimation of a proportion.

Un esempio pratico di stima di una proporzione è la stima di una probabilità di successo (di un certo processo, attività, ecc.). 

Innanzitutto si esegue una sequenza di esperimenti bernoulliani indipendenti e identicamente distribuiti (si ipotizza ciascuno di essi segua un modello $Ber(p)$, dove p è la probabilità da stimare). Tali esperimenti porteranno a una sequenza di n osservazioni (valori binari $\{0, 1\}$). Come stimatore per la probabilità p (la proporzione di eventi positivi su n tentativi) si utilizza la madia campionaria (stimatore consistente e non distorto).

Al valore stimato tramite la media campionaria, si può associare uno standard error $SE=\sqrt{\hat{p}(1-\hat{p})/n}$.

Tale proporzione stimata può essere usata poi per realizzare un modello bernoulliano.

### Define the one-way and the two-way analysis of variance models and highlight the basic assumptions.




### Describe the statistical tests on the main effects and on the interaction effect of the factors on the mean response.





## Compito del 11 giugno 2018

### Present a simple application regarding the estimation of a population variance.

Data una certa variabile numerica, si vuole farsi un'idea sulla variabilità del campione e più in generale sulla supposta varianza della popolazione. 

Per stimare la varianza dei dati, si ipotizza di avere a disposizione un campione dei dati; si usa quindi come stimatore la varianza campionaria corretta. Essa si calcola con la formula $S^2=\sum(Y-\bar{Y})/(n-1)$ (usando la media campionaria come stimatore per $\bar{Y}$ e applicando la divisione per $n-1$ invece che per $n$ per considerare la maggiore variabilità dei dati reali rispetto a quelli osservati). 

Tale strimatore è consistente e non distorto. In caso la popolazione abbia una distribuzione normale (e il campione sia scelto da osservazioni siano indipendenti e identicamente distribuite) il rapporto tra $S^2(n-1)$ e $\sigma^2$ segue una distribuzione chi-quadro (con n gradi di libertà). 

### Introduce and discuss the topic of regression models with non-Gaussian response variables.



### Consider the case of a Bernoulli distributed response and define the logistic regression model.


### With regard to a fitted logistic regression model, emphasize the interpretation of the estimated regression parameter and discuss its potential application for predicting a future binary response.

## Compito del 4 febbraio 2019

### Define the Gaussian distribution and describe its usefulness in statistical applications.

La distribuzione gaussiana (o normale) è una distribuzione di probabilità di variabili casuali continue. Essa è caratterizzata da una funzione di densità che ha come dominio tutti i numeri reali e il cui grafico è la caratteristica curva a campana. Tale curva:

- è caratterizzata da un unico picco massimo di probabilità, situato in corrispondenza del valore medio della variabile (che coincide anche con il valore mediano);
- la sua larghezza è proporzionale alla varianza della variabile;
- risulta perfettamente simmetrica;
- spostansosi dal valore medio (indifferentemente da che lato), si osserva una curva strettamente decrescente di pendenza prima crescente, poi decrescente;
- presenta delle code sempre più piatte ma mai di pendenza nulla;
- NON presenta per nessun x un valore $f(x)=0$.

La sue principali utilità in statistica sono:
* la sua utilità per modellare la distribuzione di molti fenomeni (e.g., misurazioni fisiche, l'errore casuale nella regressione lineare, ecc.), in modo diretto o attraverso trasformate;

* il suo uso (grazie al teorema del limite centrale) per approssimare la distribuzione di diversi stimatori legati a variabili casuali indipendenti e indenticamente distribuite (e.g., molte sommatorie e medie campionarie);

* l'assunzione di normalità necessaria per creare modelli di correlazione lineari; 

* l'uso della forma standardizzata (con media 1 e varianza 0) per stime di vario tipo (attraveso i quantili) e per la costruzione di strumenti più complessi (come la distribuzione Chi-Quadro, T di Student o F di Fisher); 

* il suo uso come "riferimento di base" quando si voglion descrivere dei dati (e.g., le code sono più o meno pesanti rispetto ad una gaussiana?).

### Discuss the case in which the explanatory variables are factor, with particular regard to the codification using dummy variables.

### Consider the situation with both factors and numerical explanatory variables, focusing on the particular case of models admitting different simple regression lines.

## Compito del 21 febbraio 2019

### Present a simple application regarding the estimation of the difference of the means of two independent populations.

Si prenda un certo processo industriale, la cui qualità/efficenza/"bontà" si possa misurare attraverso un valore numerico continuo. Si prenda come esempio la situazione in cui si vuole introdurre un miglioramento al processo e misurarne i benefici. 

Per quantificare i benefici introdotti, si esegue il processo N volte senza il miglioramento e poi M volte con il miglioramento. Tramite i due esperimenti, si costruiscono due campioni casuali di osservazioni indipendenti (e identicamente distribuite). 

Come misura del miglioramento introdotto, si prende la differenza tra medie campionarie $\bar{Y} - \bar{X}$. 

Si stimano per entrambi i campioni le due medie campionarie $\bar{X}$ e $\bar{Y}$. Su tali stime, ci si aspetta di avere come standard error $SEM_x=S_x/\sqrt{n}$ e $SEM_y=S_y/\sqrt{m}$. Si effettua quindi anche il calcolo per la stima di $\bar{Y} - \bar{X}$. 

Nel caso in cui i due campioni abbiano varianze diverse, l'errore quadratico medio della stima corrisponde alla somma dei due MSE, quindi lo standard error della differenza si calcola con la radice della somma dei quadrati dei due stanard error precedentemente ricavati $SED = \sqrt{SEM_x^2 + SEM_y^2}$. Se i due campioni avessero le stessa varianza invece si potrebbe effettuare il calcolo con $SED = S_p \sqrt{1/n + 1/m}$ (dove $S_p^2$ è la varianza aggregata campionaria, calcolata con due gradi di libertà).


## Compito del 28 gennaio 2020

### Describe the purpose of a (parametric) hypothesis testing procedure.

Una procedura di test d'ipotesi parametrico serve a stabilire se una certa restrizione su un parametro d'interesse è consistente con dei dati e con che confidenza si può affermare ciò.

Nei test d'ipotesi parametrici, si definiscono due ipotesi su un parametro $\theta$: Un'ipotesi nulla $H0: \theta = \theta_0$ e un'alternativa $H1: \theta \ne \theta_0$ (che volendo potrebbe essere anche solo "one-sided" - e.g., $H1: \theta > \theta_0$). A questo punto, si sceglie una statistica di test adatta allo stimatore (da applicare sotto ipotesi nulla) e si ha due possibilità.

* in base ad livello di significatività $\alpha$ e grazie alla conoscenza della statistica di test, si definisce una regione critica che, se contiene il valore osservato, posso rifiutare l'ipotesi nulla. 

* invece che definire una regione critica, calcolo per il valore osservato una probabilità $p$ (p-value), che corrisponde alla probabilità di osservare (nella statistica test) valori più lontani di $\theta$ da $\theta_0$. Se ho un p-value sufficente 

### Define the notions of significance level, critical region and p-value.

Il livello di significatività può esser visto come la probabilità $\alpha$ di incorrere in un errore di tipo 1 (rifiuto di un'ipotesi nulla $H_0$ corretta) che ritengo tollerabile. Ad esempio, se effettuo un test d'ipotesi con livello di significatività $\alpha=0.05$, vuol dire che accetto di avere una probabilità del 5% di rifiutare un'ipotesi nulla corretta.

La regione critica è l'insieme dei valori del dominio di una statistica test per i quali rifiuto un'ipotesi nulla. Corrisponde all'area per i quali la probabilità (sotto ipotesi nulla) che il valore osservato (trasformato) si trovi li è uguale al livello di significatività definito. Ad esempio per un z-test, nel caso di ipotesi alternative one-sided la regione critica è l'area prima o dopo la soglia del quantile $\alpha$ (o $1-\alpha$); nel caso di ipotesi two-sided, la regione critica sono le code oltre le soglie $\pm z_\alpha$.

Il p-value invece può esserre considerato come una misura della vicinanza dei dati all'ipotesi nulla. Nel dettaglio, esso rappresenta la prob. si osservare nella statistica test valori più estremi del valore osservato (cioè valori ancora più lontanti da quello dell'ipotesi nulla). Se ho un p-value grande, potrò dire che i dati non mi permettono di rifiutare l'ipotesi nulla; se invece ho un p-value piccolo, posso dire che i dati sono lontani dall'ipotesi nulla.


### Present a simple application concerning the testing on the equality of the means of two independent populations.

Si ipotizzi di aver raccolto due campioni casuali da due popolazioni indipendenti (e.g., misurazioni numeriche continue dello stesso fenomeno su popolazioni diversi). Per confrontare le due medie, si utilizza come stima la differenza tra le medie campionarie $\bar{X}-\bar{Y}$. Si calcola quindi tale stima, assieme allo standard error $SED=S_p*\sqrt{1/n + 1/m}$ (oppure, se i due campioni sono di varianza diversa, $SED=\sqrt{SEM_x^2+ SEM_y^2}$).

Per effettuare un test sull'ugualianza, si fissa l'ipotesi nulla $H_0: \bar{X}-\bar{Y}=0$ e l'ipotesi alternativa $H_0: \bar{X}-\bar{Y} \ne 0$. Si scelgie come statistica per il test una T di student (sotto ipotesi nulla $T= \frac{\bar{X}-\bar{Y}}{SED} \sim T(n+m-2)$); si ricava quindi il p-value per il valore osservato (nella differenza). 

Se il p-value è inferiore ad una soglia $\alpha$ con la quale sono tranquillo, rifiuto l'ipotesi nulla.

### Discuss the crucial point of selecting the explanatory variables in multiple linear regression models.

### Discuss the problem of multicollinearity and consider the potential remedies.

## Compito del 18 febbraio 2020

### Describe what are the aims of Exploratory Data Analysis and present the main graphical summaries for describing the relationship between different types (namely, categorical and numerical) of variables.

[...]

Per quanto riguarda le relazioni tra due variabili numeriche, il miglior strumento grafico è il plot. Si mette una variabile sull'ascisse e l'altra sulle ordinate del grafico, si plottano quindi tutte le osservazioni sul piano cartesiano. Spesso è comodo sovrapporre al plot alcune sintesi grafiche aggiuntive, come ad esempio una retta di regressione lineare oppure una curva LOWESS (ottenuta applicando l'omonimo modello non parametrico) per provare ad evidenziare che tipo di relazione c'è tra i dati.

Per le relazioni tra una variabile numerica e una categoriale, il principale strumento per esplorare eventuali relazioni è un grafico con più boxplot accostati. Si definisce un'asse numerica (che rappresenta la variabile numerica) e per ogni livello del fattore categoriale, si costruisce un boxplot. In questo modo si evidenzia come varia il posizionamento della variabile numerica per i diversi livelli del fattore. 

Per le relazioni tra variabili categoriali, si possono usare particolari tipi di grafici come il mosaicplot. Tale grafico rappresenta ogni possibile combinazione di livelli delle due variabili con un rettangolo; i lati dei rettangoli sono propozionali alle frequenze marginali dei rispettivi livelli, l'area invece è proporzionale alla frequenza della la combinazione.

Altri strumenti per rappresentare relazioni tra più di due variabili sono:

* i plot in 3D o le curve di livello per tre variabili numeriche;
* i plot con le osservazioni colorate per due variabili numeriche e una categoriale.

### Define the simple linear regression model and recall the t test on the nullity of the slope parameter, discussing its role in evaluating the model adequacy.

### Define the one-way analysis of variance model and describe the statistical test on the effect of the factor on the mean response

### Compare the regression model and the ANOVA model when the levels of the factor are quantitative.
