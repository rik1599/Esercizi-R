---
title: "esercizi di commento"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Compito del 1 febbraio 2017
Consider the R commands below, describe what the two codes are intended to do and explain
what is being calculated on each line. Here, simulated samples are generated from an exponential
distribution with rate=1/5.

### Codice n°1
```{r eval=FALSE}
N <- 10000
set.seed(10) #Imposta il seed per il generatore di numeri pseudo-casuale
samp <- rexp(N,1/5)  #Estrae un campione di N numeri da una distribuzione esponenziale con lambda=1/5
mean(samp) #calcola la media campionaria del campione estratto
var(samp) #calcola la varianza campionaria corretta
sd(samp) #calcola la deviazione standard campionaria corretta
```

### Codice n°2
```{r eval=FALSE}
set.seed(10)
repl<-10000
n <- 10
sampvar <- NULL
variance <- NULL
for (i in 1:repl) {
  sam <- rexp(n,1/5) #campione di 10 numeri da una distribuzione esponenziale con lambda=1/5
  sampvar <- c(sampvar,var(sam))  #vettore delle varianze campionarie corrette
  variance <- c(variance,var(sam)*9/10) #vettore delle varianze campionarie
}
mean(sampvar) #media campionaria delle varianze, stima del valore della varianza di exp(1/5)
mean(variance)
sd(sampvar) #deviazione stadard campionaria corretta per la media
sd(variance)
hist(sampvar) #mostra istogramma con i possibili valori di sampvar sulle ascisse e la frequenza di questi valori nel vettore
hist(variance)
```
Questo codice serve a visualizzare la distribuzione della varianza campionaria e della varianza campionaria corretta e li confronta, in particolare per mostrare il fatto che la varianza campionaria tende a sottostimare la varianza delle distribuzioni rispetto a quella corretta (in questo caso 25).

## Compito del 13 febbraio 2017
Consider the R commands below, describe what the two codes are intended to do and explain
what is being calculated on each line. Here, the well-known dataset Advertising is taken into
account.
```{r eval=FALSE}
Advertising<-read.csv(file="./data/Advertising.csv",header=TRUE)[,-1]
```

### Codice n°1
```{r eval=FALSE}
mod.adv <- lm(Sales~TV+Radio+Newspaper, Advertising) #creo un modello di regressione lineare utilizzando Sales come variabile di risposta e tutte le altre variabili come regressori 
summary(mod.adv) #visualizza le informazioni sul modello
summary(mod.adv)$sigma^2 #calcola la varianza dei residui a partire dal residual standard error del modello
AIC(mod.adv) #calcola l'indice AIC del modello
par(mfrow=c(2,2), pty="s", mar=c(3,2,3,2)) #visualizzazione 2x2, grafici di forma quadrata
plot(mod.adv) #mostra i plot diagnostici del modello (residual vs fitted, qq-plot, scale-location, residuals vs leverage)
par(mfrow=c(1,1))
```
calcola un modello di regressione lineare su Sales utilizzando tutte le variabili come regressori.
Ne stampa successivamente alcune statistiche e i grafici per la diagnostica del modello

### Codice n°2
```{r eval=FALSE}
mod.adv1 <- lm(Sales~TV+Radio+I(TV^2)+TV:Radio, Advertising) #secondo modello. I regressori sono TV, Radio, TV^2 e l'interazione tra TV e Radio
summary(mod.adv1) #
summary(mod.adv1)$sigma^2 #
AIC(mod.adv1) #da confrontare con AIC di mod.adv
par(mfrow=c(2,2), pty="s", mar=c(3,2,3,2))
plot(mod.adv1)
par(mfrow=c(1,1))
intc <- predict(mod.adv1, newdata=data.frame(TV=100,Radio=20),
                interval="confidence") #predice il valore di Sales sottoforma di intervallo di confidenza al 95%
intp <- predict(mod.adv1, newdata=data.frame(TV=100,Radio=20),
                interval="prediction") #predice il valore di Sales sottoforma di stima puntuale
```

## Compito del 15 febbraio 2018
Consider the R commands below, describe what the code is intended to do and explain what
is being calculated on each line. Finally, describe the R functions dbinom, pbinom, qbinom and
rbinom.

### Codice n°1
```{r eval=FALSE}
par(mfrow=c(2,2)) # grafici disposti a quadrato 2x2
xx<-seq(0,10,1) # Vettori di numeri da 0 a 10
# grafico della densità di una distribuzione binomiale con parametri n=10 e p=0.2
plot(xx,dbinom(xx,10,0.2),pch=19,ylim=c(0,0.5),
      cex.axis=1.5,xlab=" ",ylab=" ",main="A) n=10, p=0.2") # Step 3
# disegna un segmento tra il punto (0,0) e (0,10) - evidenzia il supporto.
segments(0,0,10,0,lwd=2)
```
Disegna il grafico della densità per una v.c. binomiale con n=10 e p=0.2

### Codice n°2
```{r eval=FALSE}
plot(xx,dbinom(xx,10,0.5),pch=19,ylim=c(0,0.5),lwd=2,
      cex.axis=1.5,xlab=" ",ylab=" ",main="B) n=10, p=0.5") # Step 3
segments(0,0,10,0,lwd=2)
```
Come il codice 1, ma con p=0.5

### Codice n°3
```{r eval=FALSE}
plot(xx,dbinom(xx,10,0.8),pch=19,ylim=c(0,0.5),lwd=2,
      cex.axis=1.5,xlab=" ",ylab=" ",main="C) n=10, p=0.8") # Step 3
segments(0,0,10,0,lwd=2)
```
Come il codice 1, ma con p=0.8

### Codice n°4
```{r eval=FALSE}
xx<-seq(0,20,1)
plot(xx,dbinom(xx,20,0.5),pch=19,ylim=c(0,0.5),lwd=2,
      cex.axis=1.5,xlab=" ",ylab=" ",main="D) n=20, p=0.5") # Step 3
segments(0,0,20,0,lwd=2)
par(mfrow=c(1,1))
```
Come il codice 1, ma con n=20 e p=0.5.

`dbinom`: funzione per il calcolo della f.d.p. per una v.c. con distribuzione binomiale
`pbinom`: funzione per il calcolo della funzione di ripartizione per una v.c. con distribuzione binomiale
`qbinom`: funzione per il calcolo dei quantili di una v.c. con distribuzione binomiale
`rbinom`: funzione per l'estrazione di un campione statistico random da una distribuzione binomiale

## Compito del 11 giugno 2018
Write an R code to analyze the behavior of the sampling distribution of the sample variance, as
the sample size increases. Consider 1000 simulated random samples of dimension 25, 50, 100 from
a normal distribution with mean=1 and sd=1.
```{r eval=FALSE}
# Da inserire
var25 <- NULL
var50 <- NULL
var100 <- NULL

for (i in 1:1000) {
  var25 <- c(var(rnorm(25, 1, 1))*9/10, var25)
  var50 <- c(var(rnorm(50, 1, 1))*9/10, var50)
  var100 <- c(var(rnorm(100, 1, 1))*9/10, var100)
}

plot(density(var25))
plot(density(var50))
plot(density(var100))
```
```{r}
xx <- rnorm(1000000, 1, 1)

for (size in c(25, 50, 100)) {
  sampvar <- NULL
  for (i in 1:1000) {
    sampvar <- c(sampvar, var(sample(xx, size, replace = T)))
  }
  plot(density(sampvar), main = paste("n=", size))
}
```

## Compito del 4 febbraio 2019
Consider the R commands below, describe what the three codes are intended to do and explain
what is being calculated on each line. Here, the well-known dataset USArrest is taken into account
and a Principal Component Analysis procedure is applied.

### Codice n°1
```{r eval=FALSE}
obj <- princomp(USArrests, cor=TRUE) # Calcola le componenti principali
z1 <- -obj$scores[,1] # Vettore degli scores della prima componente principale
z2 <- -obj$scores[,2] # Vettore degli scores della seconda componente principale
phi1<--obj$loadings[,1] # Vettore dei pesi della prima componente principale
phi2<--obj$loadings[,2] # Vettore dei pesi della seconda componente principale
```

### Codice n°2
```{r eval=FALSE}
obj$loadings<--obj$loadings
obj$scores<--obj$scores
biplot(obj, xlab="1st principal component", ylab="2nd principal component",
        xlim=c(-3.5,3.5), col=c(1,2), scale=0)
```
Disegna il biplot (specchiato) con le componenti principali e gli scores.

### Codice n°3
```{r eval=FALSE}
par(mfrow=c(1,2), pty="s")
plot(obj$sdev^2/4, xlab="Principal component", ylab="PVE", type='b') # Grafico della proporzione della varianza spiegata calcolata come deviazione standard delle componenti al quadrato diviso la somma delle varianze dei singoli componenti (che è 1 perchè le variabii sono standardizzate)
plot(cumsum(obj$sdev^2)/4, xlab="Principal component", ylab="Cumulative PVE", # Grafico della proporzione della varianza spiegata cumulata. cumsum fa la somma cumulata delle varianze
      ylim=c(0,1), type='b')
par(mfrow=c(1,1))
```
Disegna il grafico della proporzione della varianza spiegata e proporzione della
varianza spiegata cumulata.

## Compito del 21 febbraio 2019
Describe the R functions that can be used for model selection. Furthermore, consider the R
commands below, describe what the code is intended to do and explain what is being calculated
on each line. Here, dataset trees, which provides some measurements on felled black cherry trees,
is taken into account.

`anova`: funzione per l'analisi della varianza su modelli annidati. Si sceglie il modello con più
        regressori se il p-value del test F è sufficientemente basso

`AIC`: funzione per il calcolo degli indici AIC
`BIC`: funzione per il calolo degli indici BIC
Si sceglie il modello con statistica AIC e/o BIC più bassa

`summary`: in caso di indici AIC e BIC discordanti si sceglie il modello con indici $R^2$
          più elevati.
          
`drop1` e `add1`: valutano gli effetti, in termini di fit del modello, rimuovendo (o aggiungendo)
                un regressore al modello.

```{r eval=FALSE}
cv1 <- 0
cv2 <- 0
n <- length(trees$Volume)
i <-1
for (i in 1:n) {
  mod1i <- lm(Volume ~ Girth, data = trees[-i,])
  mod2i <- lm(Volume ~ Girth + Height, data = trees[-i,])
  mu1 <- mod1i$coefficients[1] + mod1i$coefficients[2]*trees$Girth[i]
  mu2 <- mod2i$coefficients[1] + mod2i$coefficients[2]*trees$Girth[i] +
      mod2i$coefficients[3]*trees$Height[i]
  sd1 <- sqrt(sum(mod1i$residuals^2)/(n-3))
  sd2 <- sqrt(sum(mod2i$residuals^2)/(n-4))
  cv1 <- cv1 - log(dnorm(trees$Volume[i],mu1,sd1))
  cv2 <- cv2 - log(dnorm(trees$Volume[i],mu2,sd2))
}
cv1
cv2
```
Calcolo dell'accuratezza di due modelli di regressione lineari tramite 1-fold cross validation


## Compito del 28 gennaio 2020
Consider the R commands below, describe what the code is intended to do and explain what is
being calculated on each line.

### Codice n°1
```{r eval=FALSE}
set.seed(4)
x <- seq(0,1.5,0.01)  # vettore da 0 a 1.5 con passi di 0.01
# la divisione stima la probabilità di successo di ogni elemento dei campioni 
sim1<-rbinom(1000,25,0.25)/25 # estrazione di un campione 1000 campioni da una binomiale n=25, p=0.25.
sim2<-rbinom(1000,50,0.25)/50
sim3<-rbinom(1000,100,0.25)/100
```

### Codice n°2
```{r eval=FALSE}
par(mfrow=c(1,3),pty="s") # schermata 1x3 quadrata
hist(sim1,freq=F,xlab="n=25",ylab=' ',main=' ') # istogramma delle probabilità di sim1
lines(x,dnorm(x,0.25,sqrt(0.25*0.75/10)),lwd=2,col='red') # curva di densità di una normale con media=0.25 e deviazione standard sqrt(0.25 * (1-0.25))
lines(density(sim1),lwd=2)
hist(sim2,freq=F,xlab="n=50",ylab=' ',main=' ')
lines(x,dnorm(x,0.25,sqrt(0.25*0.75/30)),lwd=2,col='red')
lines(density(sim2),lwd=2)
hist(sim3,freq=F,xlab="n=100",ylab=' ', main=' ')
lines(x,dnorm(x,0.25,sqrt(0.25*0.75/100)),lwd=2,col='red')
lines(density(sim3),lwd=2)
par(mfrow=c(1,1))
```

Mostra il teorema centrale del limite per una binomiale all'aumentare di $n$

## Compito del 18 febbraio 2020
Describe the R functions that can be used for model selection. Furthermore, consider the R
commands below, describe what the code is intended to do and explain what is being calculated
on each line. Here, dataset trees, which provides some measurements on felled black cherry trees,
is taken into account.
```{r eval=FALSE}
cv1 <- 0
cv2 <- 0
n <- length(trees$Volume)
i <-1
for (i in 1:n) {
  mod1i <- lm(Volume ~ Girth, data = trees[-i,])
  mod2i <- lm(Volume ~ Girth + Height, data = trees[-i,])
  mu1 <- mod1i$coefficients[1] + mod1i$coefficients[2]*trees$Girth[i]
  mu2 <- mod2i$coefficients[1] + mod2i$coefficients[2]*trees$Girth[i] +
  mod2i$coefficients[3]*trees$Height[i]
  sd1 <- sqrt(sum(mod1i$residuals^2)/(n-3))
  sd2 <- sqrt(sum(mod2i$residuals^2)/(n-4))
  cv1 <- cv1 - log(dnorm(trees$Volume[i],mu1,sd1))
  cv2 <- cv2 - log(dnorm(trees$Volume[i],mu2,sd2))
}
cv1
cv2
```

